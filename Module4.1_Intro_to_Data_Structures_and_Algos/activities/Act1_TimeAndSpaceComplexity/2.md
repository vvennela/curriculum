<!--title={In what time does a function grow?}-->

Going back to our function `valueSum`:

```python
value = [1, 2, 3, 4, 5] 

def valueSum(value):
    sum = 0
    for i in value:
        sum = sum + i
    return sum
```
Say `value` contains n elements. Let's run through valueSum() line by line:

`sum = 0` runs in constant time as it is simply assigning a value to the variable `sum` and only occurs once. For this line, the runtime is **c1**.

The for loop statement expresses a variable `i` iterating over each element in `value`. This creates a loop that will iterate *n* times since `value` contains *n* elements.

`sum = sum + i` occurs in constant time as well. Let's say this line runs in *c2* time. Since the loop body repeats however many times the loop is iterated, we can multiply *c2* by *n*. Now we have **c2 * n** for the runtime of the entire for loop.

Lastly, `return sum` is simply returning a number and only happens once. So, this line also runs in constant time which we'll note as **c3**.

##### Putting it all together:
If we add all the individual runtimes we found, we'll get `f(n) = c2*n + c1 + c3`. Look familiar? It's in the form of a linear equation `f(n) = a*n + b` where a and b are constants. We can predict that `valueSum()` grows in linear time.

But what does it mean to grow in linear time? As the size of the list `value` increases, the time it takes for `valueSum()` to run increases proportionally (think of it as a direct proportion).

Let's test it out with different input sizes for `value`: 

[//]: # "insert 'linear' image"

For every 1000 element increase in `value`, the time it takes for `valueSum()`to run increases roughly 0.05 milliseconds which is a linear relationship!

##### Let's look at a different function and try to predict how it will grow. 

```python
value = range(6)

def three(value):
    sum = 0
    return(sum)
```

Let's start by dividing our function by lines. 

`sum = 0` only repeats once, so we know this line will take a constant amount of time **c1**. 
`return(sum)` also only repeats once, so we can infer that this line carries out in constant time **c2**. 

Hence, we predict that `three()` grows in **constant time**. 

[//]: # "insert 'constant' image"

As shown in the image above, for any number of elements in `value`, `valueSum()` always takes about 0.001 milliseconds to run. 

![](C:\Users\ugoch\Downloads\O(1) Time.png)
Our prediction is true. Since both lines take constant time, adding them up is also still constant time, and our graph looks like a straight line. 

##### Let's look at one last function: 

```python
keypad = [[1, 2, 3], 
          [4, 5, 6],
          [7, 8, 9],
          [0]] 
def listInList(keypad):
    sum = 0
    for row in keypad:
        for i in row:
            sum += i
    return sum
```

Again, we will be trying to predict what time this function grows in. 

If we divide the function into parts, we get the lines `sum = 0`, `sum += i`, and `return sum` .
`sum = 0` repeats once, so the time for this line to process is constant.

`sum += i` is in a *for loop* so it might be intuitive to think that this line only repeats *n* times. However, this for loop is nested within another for loop, so the total number of iterations would be *n^2*.

Lastly `return sum` repeats once, so this line will be processed in constant time. 

Since our function has a line that repeats itself n^2 times, we predict that this function grows in **quadratic time**. Take a look at the tests below with varying input sizes.

[//]: # "insert 'quadratic' image"

If we graph this out, it will look like the graph below:

![](C:\Users\ugoch\Downloads\Quadratic Time.png)
Looking at the graph, we see our prediction is indeed correct. Quadratic runtime starts growing quite quickly in comparison to a linear runtime. Something else to note is that the equation for a quadratic equation is **a*n^2*+b*n*+c** where a, b and c are constants.